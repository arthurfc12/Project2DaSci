{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Arthur Carvalho\n",
    "\n",
    "Nome: Guilherme Lunetta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "!pip install emoji\n",
    "!pip install emoji_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import emoji\n",
    "import emoji_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: @tuca1209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: Arthur FC\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Trump'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "\n",
    "\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():\n",
    "    if msg.full_text.lower()[0] != 'r' and msg.full_text.lower()[1] != 't':\n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "\n",
    "            \n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "dados = pd.read_excel('Trump.xlsx')\n",
    "tweets = dados.iloc[0:,0]\n",
    "\n",
    "def limpar_caracteres(tabela, titulo):\n",
    "    a = tabela[titulo]\n",
    "    a = a.str.lower()\n",
    "\n",
    "    itens = ['.', ':', ';', '\"', \"'\", '?', '(', ')', '[',']',',', '\\n', '\\t']\n",
    "    i2 = ['?', '!']\n",
    "    emojis = emoji_list.all_emoji\n",
    "    for emoji in emojis:\n",
    "        try:\n",
    "            a = a.str.replace(emoji,\" {} \".format(emoji) )\n",
    "        except:\n",
    "            pass\n",
    "    for e in itens:\n",
    "        a = a.str.replace(e,'')\n",
    "    for e in i2:\n",
    "        a = a.str.replace(e,' {} '.format(e))\n",
    "\n",
    "    a = a.str.replace('é','e')\n",
    "    a = a.str.replace('ê','e')\n",
    "    a = a.str.replace('á','a')\n",
    "    a = a.str.replace('ã','a')\n",
    "    a = a.str.replace('ô','o')\n",
    "    a = a.str.replace('ó','o')\n",
    "    a = a.str.replace('ú','u')\n",
    "    a = a.str.replace('ç','c')\n",
    "    a = a.str.replace('í','i')\n",
    "    a = a.str.replace('@',' @')\n",
    "    a = a.str.replace(',','.')\n",
    "        \n",
    "    tabela[titulo] = a\n",
    "\n",
    "    return tabela\n",
    "\n",
    "titulo = \"Treinamento\"\n",
    "tabela = limpar_caracteres(dados, titulo)\n",
    "\n",
    "def split_tweet(tabela, titulo):\n",
    "    a = tabela[titulo].str.split(' ')\n",
    "\n",
    "    nova = pd.DataFrame()\n",
    "    nova['palavras'] = []\n",
    "\n",
    "    for lista in a:\n",
    "        for e in ['#','' , ' ', 'rt']:\n",
    "            while lista.count(e) != 0:\n",
    "                lista.remove(e)\n",
    "\n",
    "        for palavra in lista:\n",
    "            if '@' in palavra and palavra != '@realDonaldTrump':\n",
    "                lista.remove(palavra) \n",
    "            if palavra[:4] == 'http':\n",
    "                lista.remove(palavra)\n",
    "        nova = nova.append({'palavras': lista}, ignore_index=True)\n",
    "                \n",
    "    return nova\n",
    "\n",
    "nova = split_tweet(dados, titulo)\n",
    "\n",
    "\n",
    "def tabela_palavras(tabela):\n",
    "    a = tabela['palavras']\n",
    "    prob = pd.DataFrame()\n",
    "    prob['palavras'] = []\n",
    "    for lista in a:\n",
    "        for e in lista:\n",
    "            prob = prob.append({'palavras': e}, ignore_index=True)\n",
    "    \n",
    "    return prob['palavras']\n",
    "\n",
    "def tabela_tudo(tabela1, tabela2):\n",
    "    a = tabela1['palavras']\n",
    "    b = tabela2['palavras']\n",
    "    tudo = pd.DataFrame()\n",
    "    tudo['palavras'] = []\n",
    "    for lista in a:\n",
    "        for e in lista:\n",
    "            tudo = tudo.append({'palavras': e}, ignore_index=True)\n",
    "    for lista in b:\n",
    "        for e in lista:\n",
    "            tudo = tudo.append({'palavras': e}, ignore_index=True)\n",
    "    \n",
    "    return tudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vejam que coisa maravilhosa ---comite judiciar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mick jagger e sutherland criticam bolsonaro e ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@adriano 2  7  0  9  1  7  7  8   @uol nosso ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@uolnoticias esses lideres  sao esquerdista d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a tentativa de trump de negociar com o taleban...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@folha meu deus !  !  !  tomara que consigam ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nao aguento mais seguir o trump esse homem e i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>situacao triste bananeira nos eua com ameacas ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mano e incabivel pensar que o chefe do executi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>opiniao muitos afegaos morrem em ataques talib...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>barraco !   # donaldtrump detona  # johnlegend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@zekkaaa aahhh ufa obg por esclarecer a quest...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>presidente da microsoft ao lado da huawei trum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>microsoft defende huawei e chama trump de anti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>bolsonaro trata o brasil como trump trata o me...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mais uma vez a esquerda ataca o presidente nor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>@lets_dex mano eu amo o trump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ai toda vez que vejo a laura prepon me sinto t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>@mamatocrata  @sandraf 1  6  5  8  4  3  0  5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>@diothed 0 g  @brito_fdx ate agora o unico “p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>trump  2  0  2  0  a todos os herois que recon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>primeiro kim depois taleban trump segue pronto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>donald trump jair bolsonaro e mais recentement...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>o pior e que para os zumbis os minions todo o ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>donald trump esta construindo o muro mesmo com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>donald trump ataca john legend e chrissy teige...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>@georgeseia  @braziliancolle 2  o filme e bas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>trump e so charme nem o kim coreano resistiu k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>mais noticias falsas da  # cnn trump us &amp;amp t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>o mundo de fato esta mais pacifico a turminha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>o john legend afrontando o trump  😂  😂  😂  😂  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>@loveyourselfplx falando mal do trump eu prec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>matou o trump https//tco/ufzwzfquap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>@hugogloss tenho a impressao que o trump fica...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>@mundodeandy completamente isolados internaci...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tem uma coisa muito daora que o john mulaney f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>@cachuchosr  @inconseguir trump explicara iss...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>@camixx 1  2  trump=bolsonaro gente esquisita...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>@mauestevez provavelmente  !  mas os democrat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>o john legend e a chrissy teigen brigando com ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>@jornaloglobo bolsonaro adoraria ser o presid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>@anapaulavolei e ainda estao falando em impea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>o trump e o representante perfeito dessa gente...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>alguns meios de comunicacao reporteres e anali...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>@frulanis trump bananeiro  😂  😂  😂  😂  👏  👏  👏</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>em o cerco o jornalista mergulha novamente no ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>nao basta ser um dos homens mais importantes d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>saber que minha tia evangelica esculhamba o ja...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>eu fico chocado como os minions realmente acre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>@fpl 7 tsch  @educardinal eu apoio eduardo na...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>se trump pode usar o twitter pra falar merda e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>@soulscritico  @blogayra_ariana  @emanuelmm 9...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>estas ideias so de um louco como trump https//...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>@uol quem precisa de um macron quando contamo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>@renataagostini ha um distanciamento evidente...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>como e possivel bestas destas serem presidente...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>apos ataques pessoais de  # donaldtrump contra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>amanha desenvolvo mais sobre enquanto nos digl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>democratas dao mais um passo na tentativa de i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>microsoft defende huawei e chama trump de “ant...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relevancia\n",
       "2    vejam que coisa maravilhosa ---comite judiciar...           1\n",
       "7    mick jagger e sutherland criticam bolsonaro e ...           1\n",
       "8     @adriano 2  7  0  9  1  7  7  8   @uol nosso ...           1\n",
       "9     @uolnoticias esses lideres  sao esquerdista d...           1\n",
       "12   a tentativa de trump de negociar com o taleban...           1\n",
       "14    @folha meu deus !  !  !  tomara que consigam ...           1\n",
       "19   nao aguento mais seguir o trump esse homem e i...           1\n",
       "21   situacao triste bananeira nos eua com ameacas ...           1\n",
       "23   mano e incabivel pensar que o chefe do executi...           1\n",
       "25   opiniao muitos afegaos morrem em ataques talib...           1\n",
       "26   barraco !   # donaldtrump detona  # johnlegend...           1\n",
       "29    @zekkaaa aahhh ufa obg por esclarecer a quest...           1\n",
       "30   presidente da microsoft ao lado da huawei trum...           1\n",
       "33   microsoft defende huawei e chama trump de anti...           1\n",
       "38   bolsonaro trata o brasil como trump trata o me...           1\n",
       "42   mais uma vez a esquerda ataca o presidente nor...           1\n",
       "45                       @lets_dex mano eu amo o trump           1\n",
       "57   ai toda vez que vejo a laura prepon me sinto t...           1\n",
       "63    @mamatocrata  @sandraf 1  6  5  8  4  3  0  5...           1\n",
       "66    @diothed 0 g  @brito_fdx ate agora o unico “p...           1\n",
       "67   trump  2  0  2  0  a todos os herois que recon...           1\n",
       "69   primeiro kim depois taleban trump segue pronto...           1\n",
       "70   donald trump jair bolsonaro e mais recentement...           1\n",
       "76   o pior e que para os zumbis os minions todo o ...           1\n",
       "77   donald trump esta construindo o muro mesmo com...           1\n",
       "80   donald trump ataca john legend e chrissy teige...           1\n",
       "82    @georgeseia  @braziliancolle 2  o filme e bas...           1\n",
       "83   trump e so charme nem o kim coreano resistiu k...           1\n",
       "85   mais noticias falsas da  # cnn trump us &amp t...           1\n",
       "87    o mundo de fato esta mais pacifico a turminha...           1\n",
       "..                                                 ...         ...\n",
       "215  o john legend afrontando o trump  😂  😂  😂  😂  ...           1\n",
       "216   @loveyourselfplx falando mal do trump eu prec...           1\n",
       "217                matou o trump https//tco/ufzwzfquap           1\n",
       "221   @hugogloss tenho a impressao que o trump fica...           1\n",
       "222   @mundodeandy completamente isolados internaci...           1\n",
       "228  tem uma coisa muito daora que o john mulaney f...           1\n",
       "229   @cachuchosr  @inconseguir trump explicara iss...           1\n",
       "232   @camixx 1  2  trump=bolsonaro gente esquisita...           1\n",
       "235   @mauestevez provavelmente  !  mas os democrat...           1\n",
       "237  o john legend e a chrissy teigen brigando com ...           1\n",
       "240   @jornaloglobo bolsonaro adoraria ser o presid...           1\n",
       "246   @anapaulavolei e ainda estao falando em impea...           1\n",
       "248  o trump e o representante perfeito dessa gente...           1\n",
       "251  alguns meios de comunicacao reporteres e anali...           1\n",
       "256    @frulanis trump bananeiro  😂  😂  😂  😂  👏  👏  👏            1\n",
       "257  em o cerco o jornalista mergulha novamente no ...           1\n",
       "258  nao basta ser um dos homens mais importantes d...           1\n",
       "259  saber que minha tia evangelica esculhamba o ja...           1\n",
       "261  eu fico chocado como os minions realmente acre...           1\n",
       "263   @fpl 7 tsch  @educardinal eu apoio eduardo na...           1\n",
       "264  se trump pode usar o twitter pra falar merda e...           1\n",
       "273   @soulscritico  @blogayra_ariana  @emanuelmm 9...           1\n",
       "276  estas ideias so de um louco como trump https//...           1\n",
       "277   @uol quem precisa de um macron quando contamo...           1\n",
       "278   @renataagostini ha um distanciamento evidente...           1\n",
       "281  como e possivel bestas destas serem presidente...           1\n",
       "282  apos ataques pessoais de  # donaldtrump contra...           1\n",
       "292  amanha desenvolvo mais sobre enquanto nos digl...           1\n",
       "295  democratas dao mais um passo na tentativa de i...           1\n",
       "299  microsoft defende huawei e chama trump de “ant...           1\n",
       "\n",
       "[115 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevante = dados.loc[(dados['Relevancia'])==1]\n",
    "irrelevante = dados.loc[(dados['Relevancia'])==0]\n",
    "relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_teste = pd.read_excel('TrumpTeste.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "palavras_rel = tabela_palavras(split_tweet(limpar_caracteres(relevante, 'Treinamento'), 'Treinamento'))\n",
    "num_rel = palavras_rel.value_counts()\n",
    "len_rel = len(num_rel)\n",
    "\n",
    "palavras_irrel = tabela_palavras(split_tweet(limpar_caracteres(irrelevante, 'Treinamento'), 'Treinamento'))\n",
    "num_irrel = palavras_irrel.value_counts()\n",
    "len_irrel = len(num_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "teste = split_tweet(limpar_caracteres(trump_teste, 'Teste'), 'Teste')\n",
    "teste = teste.join(trump_teste['Relevancia'])\n",
    "\n",
    "tudo = tabela_tudo(split_tweet(limpar_caracteres(relevante, 'Treinamento'), 'Treinamento'),split_tweet(limpar_caracteres(irrelevante, 'Treinamento'), 'Treinamento'))\n",
    "#Total de palavras diferentes que aparecem na base de treinamento para o LaPlace.\n",
    "total_palavras = len(tudo['palavras'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "teste[\"Avaliacao\"] = pd.Series()\n",
    "\n",
    "for linha in teste[\"palavras\"]:\n",
    "    p_um = 1\n",
    "    p_zero = 1\n",
    "    p_naive = ''\n",
    "    for palavra in linha:\n",
    "        if palavra in num_rel:\n",
    "            #laplace\n",
    "            p_um *= (num_rel[palavra] + 1)/(len_rel + total_palavras)\n",
    "            \n",
    "            #print(p_um - p_zero)\n",
    "        else:\n",
    "            p_um *= 1/(len_rel + total_palavras)\n",
    "            \n",
    "            \n",
    "        if palavra in num_irrel:\n",
    "            #laplace\n",
    "            \n",
    "            p_zero *= (num_irrel[palavra] + 1)/(len_irrel + total_palavras)\n",
    "            #print(p_um - p_zero)\n",
    "        else:\n",
    "            \n",
    "            p_zero *= 1/(len_irrel + total_palavras)\n",
    "            \n",
    "    if p_um > p_zero:\n",
    "        p_naive = 'relevante'\n",
    "        teste[\"Avaliacao\"][i] = \"relevante\"\n",
    "        \n",
    "\n",
    "    elif p_um < p_zero:\n",
    "        p_naive = 'irrelevante'\n",
    "        teste[\"Avaliacao\"][i] = \"irrelevante\"\n",
    "        \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavras</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Avaliacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[se, preocupe, com, trump, macron, !, sua, apr...</td>\n",
       "      <td>0</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[quem, ainda, tem, alguma, esperanca, da, gran...</td>\n",
       "      <td>0</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[o, filme, e, sobre, o, trump]</td>\n",
       "      <td>0</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[vai, deixar, o, patrao, trump, bravinho, hein]</td>\n",
       "      <td>1</td>\n",
       "      <td>relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ninguem, liga, pra, vcs, mais, nao, perdendo,...</td>\n",
       "      <td>0</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[gente, esta, charge, do, bozo, lambendo, as, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[boris, johnson, ja, mudou, a, sua, posicao, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[placa, com, o, nome, de, trump, !, ta, doido,...</td>\n",
       "      <td>1</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[donald, trump, ataca, john, legend, e, chriss...</td>\n",
       "      <td>1</td>\n",
       "      <td>relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[obrigado, pt, por, ter, feito, do, brasil, um...</td>\n",
       "      <td>0</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            palavras  Relevancia    Avaliacao\n",
       "0  [se, preocupe, com, trump, macron, !, sua, apr...           0  irrelevante\n",
       "1  [quem, ainda, tem, alguma, esperanca, da, gran...           0  irrelevante\n",
       "2                     [o, filme, e, sobre, o, trump]           0  irrelevante\n",
       "3    [vai, deixar, o, patrao, trump, bravinho, hein]           1    relevante\n",
       "4  [ninguem, liga, pra, vcs, mais, nao, perdendo,...           0  irrelevante\n",
       "5  [gente, esta, charge, do, bozo, lambendo, as, ...           0  irrelevante\n",
       "6  [boris, johnson, ja, mudou, a, sua, posicao, s...           1  irrelevante\n",
       "7  [placa, com, o, nome, de, trump, !, ta, doido,...           1  irrelevante\n",
       "8  [donald, trump, ataca, john, legend, e, chriss...           1    relevante\n",
       "9  [obrigado, pt, por, ter, feito, do, brasil, um...           0  irrelevante"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Avaliacao</th>\n",
       "      <th>irrelevante</th>\n",
       "      <th>relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Avaliacao   irrelevante  relevante\n",
       "Relevancia                        \n",
       "0                   121          3\n",
       "1                    62         14"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid = pd.crosstab(teste[\"Relevancia\"], teste['Avaliacao'])\n",
    "valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
