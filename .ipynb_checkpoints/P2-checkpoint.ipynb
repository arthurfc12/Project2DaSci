{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados\n",
    "\n",
    "\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A equipe de marketing do presidente do Estados Unidos da América, Donald Trump, te contratou para um trabalho importante relativa à sua campanha presidencial para as eleições de 2020.<br /><br />\n",
    "Para este trabalho, sua equipe decidiu contratar dois cientistas de dados para analisar os tweets no twitter referentes ao Donald Trump e classificá-los entre relevante para a sua campanha presidencial (tweets no qual os usuários criticam ou apoiam o presidente) ou irrelevantes (tweets onde o foco não é o Donald Trump ou, por exemplo, chamadas de notícias, lugar onde opiniões não estão presentes) com o intuito de ajudar a equipe de marketing a direcionar sua campanha visto que, com as críticas, poderão ser encontrados pontos a melhorar e, com os elogios, pontos que continuarão a investir para agradar o povo, assim, maximizando a eficiência de sua campanha.<br /><br />\n",
    "Os cientistas de dados, ao verem essa proposta, decidiram utilizar seus conhecimentos da ferramenta de classificação Naive-Bayes para ensinarem seu programa a classificar os tweets como relevante ou não relevante ao assunto em questão. Para isso, terão de implementar uma versão do classificador que aprende a relevância dos tweets a partir de uma base de treinamento e irão comparar a classificação do programa com a manual, checando a performance do classificador. Feito isso, o classificador já estará pronto para classificar quaisquer tweets em relação ao assunto automaticamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicar como funciona naive bayes e dar exemplos de uso (critério de nota)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Arthur Carvalho\n",
    "\n",
    "Nome: Guilherme Lunetta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "!pip install emoji\n",
    "!pip install emoji_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import emoji\n",
    "import emoji_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: @tuca1209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: Arthur FC\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Trump'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "\n",
    "\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():\n",
    "    if msg.full_text.lower()[0] != 'r' and msg.full_text.lower()[1] != 't':\n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "\n",
    "            \n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte do excel como prova\n",
    "\n",
    "<img src='Classifica_mao.png' width='1000'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções utilizadas no projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "dados = pd.read_excel('Trump.xlsx')\n",
    "tweets = dados.iloc[0:,0]\n",
    "\n",
    "def limpar_caracteres(tabela, titulo):\n",
    "    a = tabela[titulo]\n",
    "    a = a.str.lower()\n",
    "\n",
    "    itens = ['.', ':', ';', '\"', \"'\", '?', '(', ')', '[',']',',', '\\n', '\\t']\n",
    "    i2 = ['?', '!']\n",
    "    emojis = emoji_list.all_emoji\n",
    "    for emoji in emojis:\n",
    "        try:\n",
    "            a = a.str.replace(emoji,\" {} \".format(emoji) )\n",
    "        except:\n",
    "            pass\n",
    "    for e in itens:\n",
    "        a = a.str.replace(e,'')\n",
    "    for e in i2:\n",
    "        a = a.str.replace(e,' {} '.format(e))\n",
    "\n",
    "    a = a.str.replace('é','e')\n",
    "    a = a.str.replace('ê','e')\n",
    "    a = a.str.replace('á','a')\n",
    "    a = a.str.replace('ã','a')\n",
    "    a = a.str.replace('ô','o')\n",
    "    a = a.str.replace('ó','o')\n",
    "    a = a.str.replace('ú','u')\n",
    "    a = a.str.replace('ç','c')\n",
    "    a = a.str.replace('í','i')\n",
    "    a = a.str.replace('@',' @')\n",
    "    a = a.str.replace(',','.')\n",
    "        \n",
    "    tabela[titulo] = a\n",
    "\n",
    "    return tabela\n",
    "\n",
    "titulo = \"Treinamento\"\n",
    "tabela = limpar_caracteres(dados, titulo)\n",
    "\n",
    "def split_tweet(tabela, titulo):\n",
    "    a = tabela[titulo].str.split(' ')\n",
    "\n",
    "    nova = pd.DataFrame()\n",
    "    nova['palavras'] = []\n",
    "\n",
    "    for lista in a:\n",
    "        for e in ['#','' , ' ', 'rt']:\n",
    "            while lista.count(e) != 0:\n",
    "                lista.remove(e)\n",
    "\n",
    "        for palavra in lista:\n",
    "            if '@' in palavra and palavra != '@realDonaldTrump':\n",
    "                lista.remove(palavra) \n",
    "            if palavra[:4] == 'http':\n",
    "                lista.remove(palavra)\n",
    "        nova = nova.append({'palavras': lista}, ignore_index=True)\n",
    "                \n",
    "    return nova\n",
    "\n",
    "nova = split_tweet(dados, titulo)\n",
    "\n",
    "\n",
    "def tabela_palavras(tabela):\n",
    "    a = tabela['palavras']\n",
    "    prob = pd.DataFrame()\n",
    "    prob['palavras'] = []\n",
    "    for lista in a:\n",
    "        for e in lista:\n",
    "            prob = prob.append({'palavras': e}, ignore_index=True)\n",
    "    \n",
    "    return prob['palavras']\n",
    "\n",
    "def tabela_tudo(tabela1, tabela2):\n",
    "    a = tabela1['palavras']\n",
    "    b = tabela2['palavras']\n",
    "    tudo = pd.DataFrame()\n",
    "    tudo['palavras'] = []\n",
    "    for lista in a:\n",
    "        for e in lista:\n",
    "            tudo = tudo.append({'palavras': e}, ignore_index=True)\n",
    "    for lista in b:\n",
    "        for e in lista:\n",
    "            tudo = tudo.append({'palavras': e}, ignore_index=True)\n",
    "    \n",
    "    return tudo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando os tweets entre relevantes e irrelevantes, em DataFrames separados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante = dados.loc[(dados['Relevancia'])==1]\n",
    "irrelevante = dados.loc[(dados['Relevancia'])==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lendo o excel de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_teste = pd.read_excel('TrumpTeste.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando o terreno para a suavização de Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "palavras_rel = tabela_palavras(split_tweet(limpar_caracteres(relevante, 'Treinamento'), 'Treinamento'))\n",
    "num_rel = palavras_rel.value_counts()\n",
    "len_rel = len(num_rel)\n",
    "\n",
    "palavras_irrel = tabela_palavras(split_tweet(limpar_caracteres(irrelevante, 'Treinamento'), 'Treinamento'))\n",
    "num_irrel = palavras_irrel.value_counts()\n",
    "len_irrel = len(num_irrel)\n",
    "\n",
    "teste = split_tweet(limpar_caracteres(trump_teste, 'Teste'), 'Teste')\n",
    "teste = teste.join(trump_teste['Relevancia'])\n",
    "\n",
    "tudo = tabela_tudo(split_tweet(limpar_caracteres(relevante, 'Treinamento'), 'Treinamento'),split_tweet(limpar_caracteres(irrelevante, 'Treinamento'), 'Treinamento'))\n",
    "#Total de palavras diferentes que aparecem na base de treinamento para o LaPlace.\n",
    "total_palavras = len(tudo['palavras'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "teste[\"Avaliacao\"] = pd.Series()\n",
    "\n",
    "for linha in teste[\"palavras\"]:\n",
    "    p_um = 1\n",
    "    p_zero = 1\n",
    "    p_naive = ''\n",
    "    for palavra in linha:\n",
    "        if palavra in num_rel:\n",
    "            #laplace\n",
    "            p_um *= (num_rel[palavra] + 1)/(len_rel + total_palavras)\n",
    "            \n",
    "            #print(p_um - p_zero)\n",
    "        else:\n",
    "            p_um *= 1/(len_rel + total_palavras)\n",
    "            \n",
    "            \n",
    "        if palavra in num_irrel:\n",
    "            #laplace\n",
    "            \n",
    "            p_zero *= (num_irrel[palavra] + 1)/(len_irrel + total_palavras)\n",
    "            #print(p_um - p_zero)\n",
    "        else:\n",
    "            \n",
    "            p_zero *= 1/(len_irrel + total_palavras)\n",
    "            \n",
    "    if p_um > p_zero:\n",
    "        p_naive = '1'\n",
    "        teste[\"Avaliacao\"][i] = p_naive\n",
    "        \n",
    "\n",
    "    elif p_um < p_zero:\n",
    "        p_naive = '0'\n",
    "        teste[\"Avaliacao\"][i] = p_naive\n",
    "        \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checando se o código funcionou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavras</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Avaliacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[se, preocupe, com, trump, macron, !, sua, apr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[quem, ainda, tem, alguma, esperanca, da, gran...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[o, filme, e, sobre, o, trump]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[vai, deixar, o, patrao, trump, bravinho, hein]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ninguem, liga, pra, vcs, mais, nao, perdendo,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            palavras  Relevancia  Avaliacao\n",
       "0  [se, preocupe, com, trump, macron, !, sua, apr...           0        0.0\n",
       "1  [quem, ainda, tem, alguma, esperanca, da, gran...           0        0.0\n",
       "2                     [o, filme, e, sobre, o, trump]           0        0.0\n",
       "3    [vai, deixar, o, patrao, trump, bravinho, hein]           1        1.0\n",
       "4  [ninguem, liga, pra, vcs, mais, nao, perdendo,...           0        0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando a eficiência do classificador a partir de uma crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Avaliacao</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Avaliacao   0.0  1.0\n",
       "Relevancia          \n",
       "0           121    3\n",
       "1            62   14"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid = pd.crosstab(teste[\"Relevancia\"], teste['Avaliacao'])\n",
    "valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
